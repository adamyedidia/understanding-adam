<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style><%= require("raw-loader!../static/style.css") %></style>
  <style type="text/css">@import "vis/playground.css";</style>
  
  <script src="vis/js/d3.min.js" charset="utf-8"></script>
  <script src="vis/js/underscore.js" charset="utf-8"></script>
  <script src="vis/js/rounding.js" charset="utf-8"></script>
  <script src="vis/util.js" charset="utf-8"></script>
  <script src="vis/GridWorld.js" charset="utf-8"></script>
  <script src="vis/LearnQV.js" charset="utf-8"></script>
  <script src="vis/Policy.js" charset="utf-8"></script>
  <script src="vis/Aprox.js" charset="utf-8"></script>

  <script src="vis/cliff.js" charset="utf-8"></script>
  <script src="vis/compare.js" charset="utf-8"></script>
  <script src="vis/tug.js" charset="utf-8"></script>
  <script src="vis/tug_baseline.js" charset="utf-8"></script>
  <script src="vis/reinforce.js" charset="utf-8"></script>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
  "title": "TD Learning as Intersecting Paths",
  "description": "",
  "password": "td",
  "authors": [

    {
      "author": "Chris Olah",
      "authorURL": "https://colah.github.io/",
      "affiliation": "Google Brain Team",
      "affiliationURL": "https://g.co/brain"
    }

    {
      "author": "Sam Greydanus",
      "authorURL": "https://greydanus.github.io/about.html",
      "affiliation": "Google Brain Team",
      "affiliationURL": "https://g.co/brain"
    }
  ],
  "katex": {
    "strict": false,
    "delimiters": [
      {
        "left": "$",
        "right": "$",
        "display": false
      },
      {
        "left": "$$",
        "right": "$$",
        "display": true
      }
    ]
  }
  }</script>
</d-front-matter>

<style>
  #cliff_iter .cell rect {
    fill: #e7eae7;
  }
  .cell rect {
    fill: #e7eae7;
  }
</style>

<d-title>
  <h1>TD Learning and the Effect of Merging Paths</h1>
  <p>Temporal Difference (TD) learning merges paths for greater statistical efficiency. What are the consequences?</p>
  <figure class="l-page">
    <div id="compare_hero" style="width:1000px; height:350px; margin:auto; position:relative;"> </div>
  </figure>
  <script> compare_vis(d3.select("#compare_hero"), {algs: ["MC", "TD", "Q"] }); </script> 
</d-title>

<d-article>

    <h3>Introduction</h3>
    <p>Set the scene and talk about reinforcement learning in general.</p>

    <img style="width: 100%; margin-top: 15px;" src="mockups/concepts.png"/>

    <h3>Function approximation</h3>
    <ul>
      <li>Evaluate: $$~~~f(x)$$</li>
      <li>Update: $$~~~~~f(x) ~\hookleftarrow~ y$$</li>
    </ul>

    <h2>Policy Value Iteration</h2>
    <br>

    <img style="width: 60%; margin-top: 15px;" src="mockups/policy-value-iteration.png"/>

    <p>What is value?</p>
    <br>
    <p>Time-discounted reward </p>
    <p>$$R = \sum_t \gamma^t r_t$$ </p>

    
    <h3>Cliff walking</h3>
    <br>
    <!-- <figure class="l-page">
    <div id="cliff_iter" style="width:400px; height:350px; position:relative;"> </div>
    </figure>
    <script -->> cliff_vis(d3.select("#cliff_iter")); </script>
  
  
    <h3>From value to policy</h3>
    <br>
    <ul>
      <li>Exploration</li>
      <li>Epsilon-Greedy Policies</li>
    </ul>


    <h2>Learning Value from Experience</h2>
    <br>

    <img style="width: 50%; margin-top: 15px;" src="mockups/mc-vs-td.png"/>


    <h3>Monte-Carlo Learning</h3>
    <br>
    <p>Value of state is average return.</p>
  
    <br>
    <p>$$V(s_t) ~\hookleftarrow~ R_t~~~~~~~~~~~~$$</p>
    <br>
    <p>$$V(s_t) ~\hookleftarrow~ \sum_i \gamma^i r_{t+i}$$</p>
  

    
    <figure class="l-page">
    <div id="compare1" style="width:300px; height:500px; margin:auto; position:relative;"> </div>
    </figure>
    <script> compare_vis(d3.select("#compare1"), {algs: ["MC"] }); </script>


    <h3>Temporal Difference Learning</h3>
    <br>
    <p>Merge paths for greater statistical efficiency.</p>

    <br>
    <p>$$V(s_t) ~\hookleftarrow~ r_t + \gamma V(s_{t+1})$$</p>
  

    
    <figure class="l-page">
    <div id="compare2" style="width:650px; height:500px; margin:auto; position:relative;"> </div>
    </figure>
    <script> compare_vis(d3.select("#compare2"), {algs: ["MC", "TD"] }); </script>


    <h3>Re-weighting the future</h3>
    <br>
    <p>State-Action Values</p>
    <p>Easier to make policies</p>
    <p>MC and TD still work.</p>
    <p>“Q functions are split value state value functions.” How do we merge them back </p>

    <p>Why Q-learning is overconfident</p>
    <br>

    <h2>Function approximation</h2>
    <br>
    <p>Neural networks, so forth</p>

    <img style="width: 100%; margin-top: 15px" src="mockups/averagers.png"/>

    <h2>Playground</h2>
    <br>
    <div id="playground"></div>
    <script src="vis/Playground.js" charset="utf-8"></script>

</d-article>



<d-appendix>
  <h3>Acknowledgments</h3>
  <p>
  </p>


  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<d-bibliography src="bibliography.bib"></d-bibliography>

</body>
